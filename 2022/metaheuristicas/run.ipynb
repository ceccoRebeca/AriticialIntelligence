{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9150b610",
   "metadata": {},
   "source": [
    "## Segundo Trabalho de Inteligência Artificial e Sistemas Inteligentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc34dcd",
   "metadata": {},
   "source": [
    "Rebeca Cecco de Oliveira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0369c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from dinoAI import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4b8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed0caec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\user\\anaconda3\\lib\\site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce46ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_KeyClassifier():\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "\n",
    "    def keySelector(self, distance, speed, obType):\n",
    "        self.state = sorted (self.state, key = first)\n",
    "    for s,d in self.state:\n",
    "       if speed < s:\n",
    "          limDist = d\n",
    "          break\n",
    "    if distance <= limDist:\n",
    "       if isinstance(obType, Bird):\n",
    "           return \"K_DOWN\"\n",
    "       else:\n",
    "           return \"K_UP\"\n",
    "    return \"K_NO\"\n",
    "\n",
    "    def updateState(self, state):\n",
    "        self.state = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03f54f",
   "metadata": {},
   "source": [
    "### Implementação do KM Centroids do T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae3f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansCentroidsClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimator='kmeans', argv=None, n_clusters=8):\n",
    "        self._estimator = estimator\n",
    "        self._n_clusters = n_clusters\n",
    "        self._argv = argv\n",
    "\n",
    "        if estimator == 'kmeans':\n",
    "          self._est = KMeans(n_clusters)\n",
    "        else:\n",
    "          raise Exception('Estimator not definied!')\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        # Geting centroids with estimator\n",
    "        self.__groups = [self._est.fit(X[y == c]).cluster_centers_ for c in self.classes_]\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        predicted = [self.classes_[np.argmin([min([np.linalg.norm(x - c) for c in g]) for g in self.__groups])] for x in X]\n",
    "        return np.array(predicted)\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'estimator': self._estimator,\n",
    "                'n_clusters': self._n_clusters,\n",
    "                'argv': self._argv}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c3a59",
   "metadata": {},
   "source": [
    "### Implementação da MetaHeurística Escolida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ce741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA():\n",
    "    def __init__(self, n_clusters, argv):\n",
    "        self.k_ = n_clusters\n",
    "        self.pop_size_ = argv['pop_size']\n",
    "        self.iter_max_ = argv['iter_max']\n",
    "        self.cross_ratio_ = argv['cross_ratio']\n",
    "        self.mut_ratio_ = argv['mut_ratio']\n",
    "        self.max_time_ = argv['max_time']\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Check that X have correct shape\n",
    "        X = check_array(X)\n",
    "\n",
    "        self.X_ = X\n",
    "\n",
    "        # Geting centroids with estimator\n",
    "        solution = self.genetic(X, self.k_, self.pop_size_, self.iter_max_, \n",
    "                                       self.cross_ratio_, self.mut_ratio_, self.max_time_)\n",
    "        self.cluster_centers_ = solution['cluster_centers_'],\n",
    "        self.sse_ = solution['sse_'],\n",
    "        self.clusters_ = solution['clusters_']\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        predicted = [self.classes_[np.argmin([np.linalg.norm(x - g) for g in self.__solution['cluster_centers_']])] for x in X]\n",
    "        return np.array(predicted)\n",
    "\n",
    "\n",
    "    def __available_closest_items(self, cluster, available_items, n):\n",
    "        # n items more closet to centroid of cluster\n",
    "        n = min(n, len(available_items))\n",
    "        evaluations = [self.__evaluate_cluster(cluster + [i]) for i in available_items]\n",
    "        closest = np.argpartition([e['sum_dist'] for e in evaluations], range(n))[:n]\n",
    "        return closest\n",
    "\n",
    "    def hill_climbing(self, items, k):\n",
    "        num_best = k\n",
    "        available_items = list(range(len(items)))\n",
    "        np.random.shuffle(available_items)\n",
    "        # choose the firsts items of clusters randomly\n",
    "        clusters = [[items[available_items.pop()]] for _ in range(k)]\n",
    "\n",
    "        current_cluster = 0\n",
    "        while available_items:\n",
    "            closest = self.__available_closest_items(clusters[current_cluster], [items[p] for p in available_items], num_best)\n",
    "            choiced = available_items[closest[np.random.randint(len(closest))]]\n",
    "            clusters[current_cluster].append(items[choiced])\n",
    "            available_items.remove(choiced)\n",
    "            current_cluster = (current_cluster + 1) % k\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def __evaluate_cluster(self, cluster):\n",
    "        # euclidean norm\n",
    "        items = [s['coord'] for s in cluster]\n",
    "        mu = np.average(items, axis=0) # centroid\n",
    "        \n",
    "        norm2 = [np.linalg.norm(i-mu) for i in items]\n",
    "        return {'sum_dist': sum(norm2), 'dist': norm2, 'mu': mu.tolist(), 'items': cluster}\n",
    "\n",
    "    def __evaluate_clusters(self, clusters):\n",
    "        states = [self.__evaluate_cluster(cluster) for cluster in clusters]\n",
    "        return states\n",
    "\n",
    "    def __objective_function(self, states):\n",
    "        # SSE metric\n",
    "        sse = sum([state['sum_dist'] for state in states])\n",
    "        return sse\n",
    "\n",
    "    def __random_state(self, states):\n",
    "        n = len(states)-1\n",
    "        if n <= 1:\n",
    "            return states[0]\n",
    "\n",
    "        index = np.random.randint(0, n)\n",
    "        return states[index]\n",
    "\n",
    "    def __initial_population(self, n, items, k):\n",
    "        pop = [self.__evaluate_clusters(self.hill_climbing(items, k)) for _ in range(n)]\n",
    "        return pop\n",
    "\n",
    "    def __selection(self, population, n, n_tournament):\n",
    "        # by tournament\n",
    "        N = len(population)\n",
    "        if n >= N:\n",
    "            return population\n",
    "        if n_tournament > N:\n",
    "            n_tournament = N\n",
    "\n",
    "        selecteds = np.random.choice(range(0, len(population)), size=n_tournament, replace=False)\n",
    "        selecteds.sort()\n",
    "        values = [self.__objective_function(population[i]) for i in selecteds]\n",
    "        pos_ordered = np.argpartition(values, range(n))[-n:]\n",
    "        return [population[p] for p in pos_ordered]\n",
    "\n",
    "    def __crossover(self, dad, mom):\n",
    "        # son product of an egg fertilized by a sperm\n",
    "        sperm = self.__random_state(dad)['items']\n",
    "        # take all groups that not contain the sperm, and remove it too\n",
    "        egg = [e for e in [[n for n in m['items'] if n not in sperm] for m in mom] if e]\n",
    "        son = egg + [sperm]\n",
    "\n",
    "        k = len(dad)\n",
    "        while len(son) > k: # concatenate smaller groups\n",
    "            smallers = np.argpartition([len(s) for s in son], range(2))[:2]\n",
    "            son[smallers[0]] += son[smallers[1]]\n",
    "            del son[smallers[1]]\n",
    "\n",
    "        while len(son) < k: # separate larger groups\n",
    "            larger = np.argmax([len(s) for s in son])\n",
    "            half = len(son[larger])//2\n",
    "            son += [son[larger][:half]] + [son[larger][half:]]\n",
    "            del son[larger]\n",
    "\n",
    "        return self.__evaluate_clusters(son)\n",
    "\n",
    "    def __mutation(self, items, k):\n",
    "        # new individual\n",
    "        return self.__evaluate_clusters(self.hill_climbing(items, k))\n",
    "\n",
    "    def __convergent(self, population):\n",
    "        clusters_0 = [sorted([i['id'] for i in p['items']]) for p in population[0]]\n",
    "        clusters = [[sorted([i['id'] for i in clusters['items']]) for clusters in states] for states in population]\n",
    "        return all(c == clusters_0 for c in clusters)\n",
    "\n",
    "    def __evaluate_population(self, population):\n",
    "        return sum([self.__objective_function(p) for p in population], [])\n",
    "\n",
    "    def __offspring(self, population, n):\n",
    "        best_index = np.argpartition([sum([q['sum_dist'] for q in p]) for p in population], range(n))[:n]\n",
    "        return [population[i] for i in best_index]\n",
    "\n",
    "    def genetic(self, X, k, pop_size, iter_max, cross_ratio, mut_ratio, max_time):\n",
    "        items = [{'id': x, 'coord': y} for x, y in zip(range(len(X)), X)]\n",
    "        n_tournament = 3\n",
    "        half_pop = pop_size//2\n",
    "        pop = self.__initial_population(pop_size, items, k)\n",
    "        iter = 0\n",
    "        end = 0\n",
    "\n",
    "        start = time.process_time()\n",
    "        while True:\n",
    "            new_pop = pop.copy()\n",
    "            for _ in range(half_pop): # everyone can cross\n",
    "                if np.random.uniform(0, 1, 1) <= cross_ratio:\n",
    "                    parents = self.__selection(pop, 2, n_tournament)\n",
    "                    new_pop.append(self.__crossover(parents[0], parents[1]))\n",
    "                if np.random.uniform(0, 1, 1) <= mut_ratio:\n",
    "                    new_pop.append(self.__mutation(items, k))\n",
    "            pop = self.__offspring(new_pop, pop_size)\n",
    "            val_pop = self.__evaluate_population(pop)\n",
    "\n",
    "            iter += 1\n",
    "            end = time.process_time()\n",
    "            if iter >= iter_max:\n",
    "                br = 'iteration'\n",
    "                break\n",
    "            if end-start > max_time:\n",
    "                br = 'time'\n",
    "                break\n",
    "            if self.__convergent(pop):\n",
    "                br = 'convergence'\n",
    "                break\n",
    "\n",
    "        best_individual = self.__offspring(pop, 1)[0]\n",
    "        return {'cluster_centers_': [b['mu'] for b in best_individual],\n",
    "                'sse_': [b['sum_dist'] for b in best_individual],\n",
    "                'clusters_': [[c['coord'] for c in b['items']] for b in best_individual]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd6cad",
   "metadata": {},
   "source": [
    "## Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86111f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\AriticialIntelligence\\2022\\metaheuristicas\\dinoAI.py:352\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    350\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m23\u001b[39m,\u001b[38;5;241m300\u001b[39m), (\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m400\u001b[39m), (\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m500\u001b[39m), (\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m600\u001b[39m)]\n\u001b[0;32m    351\u001b[0m aiPlayer \u001b[38;5;241m=\u001b[39m KeySimplestClassifier(initial_state)\n\u001b[1;32m--> 352\u001b[0m best_state, best_value \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_ascent\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m aiPlayer \u001b[38;5;241m=\u001b[39m KeySimplestClassifier(best_state)\n\u001b[0;32m    354\u001b[0m res, value \u001b[38;5;241m=\u001b[39m manyPlaysResults(rounds)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\AriticialIntelligence\\2022\\metaheuristicas\\dinoAI.py:328\u001b[0m, in \u001b[0;36mgradient_ascent\u001b[1;34m(state, max_time)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m neighborhood: \n\u001b[0;32m    327\u001b[0m     aiPlayer \u001b[38;5;241m=\u001b[39m KeySimplestClassifier(s)\n\u001b[1;32m--> 328\u001b[0m     res, value \u001b[38;5;241m=\u001b[39m \u001b[43mmanyPlaysResults\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m>\u001b[39m max_value:\n\u001b[0;32m    330\u001b[0m         state \u001b[38;5;241m=\u001b[39m s\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\AriticialIntelligence\\2022\\metaheuristicas\\dinoAI.py:343\u001b[0m, in \u001b[0;36mmanyPlaysResults\u001b[1;34m(rounds)\u001b[0m\n\u001b[0;32m    341\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mround\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (rounds):\n\u001b[1;32m--> 343\u001b[0m     results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mplayGame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    344\u001b[0m npResults \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(results)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results, npResults\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m npResults\u001b[38;5;241m.\u001b[39mstd())\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\AriticialIntelligence\\2022\\metaheuristicas\\dinoAI.py:286\u001b[0m, in \u001b[0;36mplayGame\u001b[1;34m()\u001b[0m\n\u001b[0;32m    282\u001b[0m cloud\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    284\u001b[0m score()\n\u001b[1;32m--> 286\u001b[0m \u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29de7d",
   "metadata": {},
   "source": [
    "### Resultados da Execução do Professor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73074cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "placares_prof = [3237, 3217, 3230, 3300, 4136, 3224, 3225, 3229, 3238, 4046, 3006, 3237, 3280, 3280, 3284, 3251, 3232, 3277, 3217, 3278, 3272, 3234, 3229, 3397, 3015, 3270, 3251, 2713, 3216, 3371]\n",
    "media_prof = 3279.733333333333\n",
    "std_prof = 248.07954817401256\n",
    "media_menos_desvio_prof = 3031.6537851593207"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
